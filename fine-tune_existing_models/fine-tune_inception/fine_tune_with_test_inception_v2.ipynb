{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right reserved by #https://github.com/apache/incubator-mxnet/blob/master/docs/tutorials/onnx/fine_tuning_gluon.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, autograd\n",
    "from mxnet.gluon.data.vision.datasets import ImageFolderDataset\n",
    "from mxnet.gluon.data import DataLoader\n",
    "import mxnet.contrib.onnx as onnx_mxnet\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_folder = \"images\"\n",
    "utils_file = \"utils.py\" # contain utils function to plot nice visualization\n",
    "base_url = \"https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/doc/tutorials/onnx/{}?raw=true\"\n",
    "mx.test_utils.download(base_url.format(utils_file), fname=utils_file)\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://s3.amazonaws.com/download.onnx/models/opset_3/\"\n",
    "current_model = \"inception_v2\"\n",
    "model_folder = \"model\"\n",
    "archive_file = \"{}.tar.gz\".format(current_model)\n",
    "archive_path = os.path.join(model_folder, archive_file)\n",
    "url = \"{}{}\".format(base_url, archive_file)\n",
    "onnx_path = os.path.join(model_folder, current_model, 'model.onnx')\n",
    "\n",
    "# Download the zipped model\n",
    "mx.test_utils.download(url, dirname = model_folder)\n",
    "\n",
    "# Extract the model\n",
    "if not os.path.isdir(os.path.join(model_folder, current_model)):\n",
    "    print('Extracting {} in {}...'.format(archive_path, model_folder))\n",
    "    tar = tarfile.open(archive_path, \"r:gz\")\n",
    "    tar.extractall(model_folder)\n",
    "    tar.close()\n",
    "    print('Model extracted.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data/train, data/val, data/test directories and paste images accordingly \n",
    "training_path = \"data/train\"\n",
    "print(training_path)\n",
    "testing_path = \"data/val\"\n",
    "print(testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDGE = 224\n",
    "SIZE = (EDGE, EDGE)\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(image, label):\n",
    "    resized = mx.image.resize_short(image, EDGE)\n",
    "    cropped, crop_info = mx.image.center_crop(resized, SIZE)\n",
    "    transposed = nd.transpose(cropped, (2,0,1))\n",
    "    return transposed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ImageFolderDataset(root=training_path)\n",
    "dataset_test = ImageFolderDataset(root=testing_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train.transform(transform, lazy=False), batch_size=BATCH_SIZE, last_batch='rollover',\n",
    "                              shuffle=True, num_workers=NUM_WORKERS)\n",
    "dataloader_test = DataLoader(dataset_test.transform(transform, lazy=False), batch_size=BATCH_SIZE, last_batch='rollover',\n",
    "                             shuffle=False, num_workers=NUM_WORKERS)\n",
    "print(\"Train dataset: {} images, Test dataset: {} images\".format(len(dataset_train), len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = dataset_train.synsets\n",
    "NUM_CLASSES = len(categories)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "plt.imshow((transform(dataset_train[N][0], 0)[0].asnumpy().transpose((1,2,0))))\n",
    "plt.axis('off')\n",
    "print(categories[dataset_train[N][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym, arg_params, aux_params = onnx_mxnet.import_model(onnx_path)\n",
    "def get_layer_output(symbol, arg_params, aux_params, layer_name):\n",
    "    all_layers = symbol.get_internals()\n",
    "    net = all_layers[layer_name+'_output']\n",
    "    net = mx.symbol.Flatten(data=net)\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if k in net.list_arguments()})\n",
    "    new_aux = dict({k:aux_params[k] for k in aux_params if k in net.list_arguments()})\n",
    "    return (net, new_args, new_aux)\n",
    "\n",
    "sym.get_internals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sym, new_arg_params, new_aux_params = get_layer_output(sym, arg_params, aux_params, 'flatten0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.gpu() if mx.context.num_gpus() > 0 else mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    pre_trained = gluon.nn.SymbolBlock(outputs=new_sym, inputs=mx.sym.var('data_0'))\n",
    "net_params = pre_trained.collect_params()\n",
    "for param in new_arg_params:\n",
    "    if param in net_params:\n",
    "        net_params[param]._load_init(new_arg_params[param], ctx=ctx)\n",
    "for param in new_aux_params:\n",
    "    if param in net_params:\n",
    "        net_params[param]._load_init(new_aux_params[param], ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = gluon.nn.Dense(NUM_CLASSES)\n",
    "dense_layer.initialize(mx.init.Xavier(magnitude=2.24), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gluon.nn.HybridSequential()\n",
    "net.hybridize()\n",
    "with net.name_scope():\n",
    "    net.add(pre_trained)\n",
    "    net.add(dense_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001\n",
    "WDECAY = 0.00001\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctx = mx.gpu() \n",
    "net.collect_params().initialize(ctx=ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', \n",
    "                        {'learning_rate': LEARNING_RATE,\n",
    "                         'wd':WDECAY,\n",
    "                         'momentum':MOMENTUM})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy_gluon(data_iterator, net):\n",
    "    num_instance = 0\n",
    "    sum_metric = nd.zeros(1,ctx=ctx, dtype=np.int32)\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.astype(np.float32).as_in_context(ctx)\n",
    "        label = label.astype(np.int32).as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        prediction = nd.argmax(output, axis=1).astype(np.int32)\n",
    "        num_instance += len(prediction)\n",
    "        sum_metric += (prediction==label).sum()\n",
    "    accuracy = (sum_metric.astype(np.float32)/num_instance)\n",
    "    return accuracy.asscalar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Untrained network Test Accuracy: {0:.4f}\".format(evaluate_accuracy_gluon(dataloader_test, net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = 0\n",
    "for epoch in range(10):\n",
    "    for i, (data, label) in enumerate(dataloader_train):\n",
    "        data = data.astype(np.float32).as_in_context(ctx)\n",
    "        label = label.as_in_context(ctx)\n",
    "\n",
    "        if i%20==0 and i >0:\n",
    "            print('Batch [{0}] loss: {1:.4f}'.format(i, loss.mean().asscalar()))\n",
    "\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "\n",
    "    nd.waitall() # wait at the end of the epoch    \n",
    "    new_val_accuracy = evaluate_accuracy_gluon(dataloader_test, net)    \n",
    "    print(\"Epoch [{0}] Test Accuracy {1:.4f} \".format(epoch, new_val_accuracy))\n",
    "\n",
    "#     # We perform early-stopping regularization, to prevent the model from overfitting\n",
    "#     if val_accuracy > new_val_accuracy:\n",
    "#         print('Validation accuracy is decreasing, stopping training')\n",
    "#         break\n",
    "    val_accuracy = new_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save net parameters\n",
    "net.export(current_model, 100)\n",
    "saved_model = current_model + '.params'\n",
    "print (saved_model)\n",
    "net.save_parameters(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img):\n",
    "    return nd.array(np.expand_dims(np.transpose(img, (2,0,1)),axis=0).astype(np.float32), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import cv2\n",
    "import psutil\n",
    "\n",
    "#This is the path of the images for testing\n",
    "path = os.getcwd() + '/data/test'\n",
    "\n",
    "#folders = []\n",
    "\n",
    "files = os.listdir(path)\n",
    "#print (files)\n",
    "\n",
    "images = {}\n",
    "false_assum = {}\n",
    "\n",
    "for file in files:\n",
    "   if 'hazard' in file:\n",
    "      images.update({file : 'hazard'})\n",
    "   elif 'clean' in file:\n",
    "      images.update({file : 'clean'})\n",
    "\n",
    "#print (images)\n",
    "\n",
    "total_time = 0\n",
    "for key in images:\n",
    "   print ('\\n\\nImage name : ',key, 'Tag: ' , images[key], 'floor and the classification result is : ' )\n",
    "   \n",
    "   img = cv2.imread(path+'/'+key)\n",
    "   img = cv2.resize(img,(224,224))\n",
    "   #img = np.reshape(img,[1,224,224,3])\n",
    "   #image = tf.cast(img, tf.float32)\n",
    "   image = transform(img)\n",
    "   start_time = time.time()\n",
    "   classes = net(image)\n",
    "   total_time = total_time + (time.time()-start_time)\n",
    "   print(classes)\n",
    "   pid = os.getpid()\n",
    "   py = psutil.Process(pid)\n",
    "   memoryUse = py.memory_info()[0]/2.**30  # memory use in GB...I think\n",
    "   cpuusage = py.cpu_percent()\n",
    "   print('memory use:', memoryUse)\n",
    "   print('cpu use:', cpuusage)\n",
    "   if classes[0][0] > classes[0][1]:\n",
    "        res = 'clean'\n",
    "        print('clean')\n",
    "   else:\n",
    "        res = 'hazard'\n",
    "        print('hazard')\n",
    "   \n",
    "#    print(\"---%s seconds ---\" % (time.time() - start_time))\n",
    "   print(\"Image Name\", key ,\"classify as : \", res )\n",
    "   if images[key] in res:\n",
    "      images[key] = 1\n",
    "   else:\n",
    "      images[key] = 0\n",
    "      false_assum.update({key: 0})\n",
    "print(\"Total avg inference time: \", total_time/138)\n",
    "\n",
    "print (\"List of wrong assumtion : \", false_assum)\n",
    "print ('########## Final result #########')\n",
    "print ('Total right assumtion : ', sum(images.values()), '\\nTotal worng assumtion : ', len(images)-sum(images.values()), '\\nModel accuracy = ', round((sum(images.values())*100)/len(images), 3), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of predictions to show (optional)\n",
    "TOP_P = 1\n",
    "images = os.listdir(\"images\")\n",
    "\n",
    "# Convert img to format expected by the network\n",
    "def transform(img):\n",
    "    return nd.array(np.expand_dims(np.transpose(img, (2,0,1)),axis=0).astype(np.float32), ctx=ctx)\n",
    "\n",
    "# Load and transform the test images\n",
    "caltech101_images_test = [plt.imread(os.path.join(image_folder, \"{}\".format(img))) for img in images]\n",
    "caltech101_images_transformed = [transform(img) for img in caltech101_images_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(net, data):\n",
    "    results = []\n",
    "    for batch in data:\n",
    "        outputs = net(batch)\n",
    "        results.extend([o for o in outputs.asnumpy()])\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image should be 224*224\n",
    "result = run_batch(net, caltech101_images_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(caltech101_images_test, result, categories, TOP_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
